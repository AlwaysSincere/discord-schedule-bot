import openai
import os
import json
import asyncio
import re
from datetime import datetime
import pytz

class ScheduleClassifier:
    def __init__(self):
        """AI ì¼ì • ë¶„ë¥˜ê¸° ì´ˆê¸°í™”"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        openai.api_key = api_key
        print("âœ… OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ (v0.28.1)")
        
        self.schedules = []
        self.non_schedules = []
        
    def create_classification_prompt(self, messages):
        """ë©”ì‹œì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì •ë°€ ì¡°ì • ë²„ì „)"""
        
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
        
        prompt = f"""ë‹¹ì‹ ì€ ìŒì•… ë™ì•„ë¦¬ Discord ë©”ì‹œì§€ì—ì„œ **ì‹¤ì œ êµ¬ì²´ì ì¸ ì¼ì •**ì„ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**í˜„ì¬ ì‹œê°„**: {now.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')} (í•œêµ­ì‹œê°„)

**âœ… ë°˜ë“œì‹œ ì¼ì •ìœ¼ë¡œ ë¶„ë¥˜í•´ì•¼ í•˜ëŠ” ê²ƒë“¤**:
1. **êµ¬ì²´ì  ì‹œê°„ + í–‰ë™**: "ì˜¤ëŠ˜ 8ì‹œ í•©ì£¼", "2ì‹œ 20ë¶„ ì½œíƒ€ì„ì…ë‹ˆë‹¤"
2. **í™•ì¸í˜• ì§ˆë¬¸**: "ì˜¤ëŠ˜ í•©ì£¼ ë§ì£ ?", "ì‹œê°„ ê·¸ëŒ€ë¡œ í•˜ì£ ?"
3. **ì¼ì • ê³µì§€**: "ì½œíƒ€ì„ì…ë‹ˆë‹¤", "ë¦¬í—ˆì„¤ì…ë‹ˆë‹¤" (ì‹œê°„ í¬í•¨)
4. **ë¯¸ë˜ ì¼ì • ì–¸ê¸‰**: "ë‚´ì¼ ë¦¬í—ˆì„¤", "8ì›” 8ì¼ ë¦¬í—ˆì„¤"

**âŒ ì ˆëŒ€ ì¼ì •ì´ ì•„ë‹Œ ê²ƒë“¤**:
1. **ë‹¨ìˆœ ëŒ€ë‹µ**: "í•©ë‹ˆë‹¤", "ë§ìŠµë‹ˆë‹¤" (êµ¬ì²´ì  ì œì•ˆ ì—†ì´)
   ì˜ˆ: "ì•„ í•©ì£¼ì—°ìŠµì€í•©ë‹ˆë‹¤" â†’ ë‹¨ìˆœ ëŒ€ë‹µ
2. **ì¼ë°˜ ì§ˆë¬¸**: "~í•  ì‹œê°„ ìˆë‚˜ìš”?", "ì–´ë–»ê²Œ í•´ìš”?"
   ì˜ˆ: "ê¸°íƒ€ ë°”ê¿€ ì‹œê°„ ìˆê°°ì£ ?" â†’ ì¼ë°˜ ì§ˆë¬¸
3. **ìˆœì„œ/ë°©ë²• ì„¤ëª…**: "ìˆœì„œëŒ€ë¡œ", "ë¨¼ì €", "ë°©ë²•ì€"
   ì˜ˆ: "ë‹¤ìŒ ë¦¬í—ˆì„¤ì€ ìˆœì„œëŒ€ë¡œ ë¼ì´íŠ¸ ë¨¼ì €" â†’ ìˆœì„œ ì„¤ëª…
4. **ì‹œê°„ ì„¤ëª…**: "~ì€ 2ì‹œê°„ ì •ë„", "~ì€ 15ë¶„"
   ì˜ˆ: "ì„œê³¡ì€ 2ì‹œê°„ ì •ë„" â†’ ì‹œê°„ ì„¤ëª…
5. **ì‹ì‚¬/ì•ˆì£¼ ì´ì•¼ê¸°**: "ë“œì‹¤", "ë¨¹ì„", "ë§ˆì‹¤"
   ì˜ˆ: "í•©ì£¼ëë‚˜ê³  ë“œì‹¤ ì•ˆì£¼ë‘" â†’ ì•ˆì£¼ ì´ì•¼ê¸°
6. **ê¸°ìˆ /ì¥ë¹„ ë…¼ì˜**: "ì„¸íŒ…", "ì¥ë¹„", "ë…¹í™”", "ì´¬ì˜" (ì¼ì • ë§¥ë½ ì—†ì´)

**ì •í™•í•œ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
â–¡ êµ¬ì²´ì ì¸ ì‹œê°„ì´ë‚˜ ë‚ ì§œê°€ ìˆëŠ”ê°€?
â–¡ ëª…í™•í•œ í–‰ë™ ê³„íšì´ ìˆëŠ”ê°€? 
â–¡ ë‹¨ìˆœ ëŒ€ë‹µì´ë‚˜ ì§ˆë¬¸ì´ ì•„ë‹Œê°€?
â–¡ ìˆœì„œ ì„¤ëª…ì´ë‚˜ ì‹œê°„ ì„¤ëª…ì´ ì•„ë‹Œê°€?

**ì‹¤ì œ ë¶„ë¥˜ ì˜ˆì‹œ**:
âœ… "ì˜¤ëŠ˜ 2ì‹œ 20ë¶„ ì½œíƒ€ì„ì…ë‹ˆë‹¤" â†’ ì¼ì • (ê³µì§€+ì‹œê°„)
âœ… "ì˜¤ëŠ˜í•©ì£¼ëŠ”8ì‹œ ê·¸ëŒ€ë¡œ í•˜ì£ ?" â†’ ì¼ì • (í™•ì¸+ì‹œê°„)
âœ… "8ì›” 8ì¼ ë¦¬í—ˆì„¤ë•Œë„ ì´¬ì˜ í•„ìš”í•˜ì‹ ê°€ìš”?" â†’ ì¼ì • (ë‚ ì§œ+í–‰ë™)
âŒ "ì•„ í•©ì£¼ì—°ìŠµì€í•©ë‹ˆë‹¤" â†’ ë‹¨ìˆœ ëŒ€ë‹µ
âŒ "ê³µì—°ë‚ ì€ ê¸°íƒ€ ë°”ê¿€ ì‹œê°„ ìˆê°°ì£ ?" â†’ ì¼ë°˜ ì§ˆë¬¸
âŒ "ì„œê³¡ì€ 2ì‹œê°„ ì •ë„" â†’ ì‹œê°„ ì„¤ëª…
âŒ "í•©ì£¼ëë‚˜ê³  ë“œì‹¤ ì•ˆì£¼ë‘" â†’ ì•ˆì£¼ ì´ì•¼ê¸°

**ë¶„ë¥˜ ê¸°ì¤€**:
- í™•ì‹ ë„ 92% ì´ìƒì´ì–´ì•¼ ì¼ì •ìœ¼ë¡œ ë¶„ë¥˜
- ì˜ì‹¬ìŠ¤ëŸ¬ìš°ë©´ ì¼ì • ì•„ë‹˜ìœ¼ë¡œ ë¶„ë¥˜ (ì •í™•ë„ ìš°ì„ )

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€:

```json
{{
  "schedules": [
    {{
      "message_id": "ID",
      "content": "ë‚´ìš©",
      "author": "ì‘ì„±ì",
      "channel": "ì±„ë„",
      "created_at": "ì‹œê°„",
      "schedule_type": "í•©ì£¼|ë¦¬í—ˆì„¤|ì—°ìŠµ|ê³µì—°|ì½œíƒ€ì„",
      "confidence": 0.95,
      "extracted_info": {{
        "when": "êµ¬ì²´ì  ì‹œê°„",
        "what": "êµ¬ì²´ì  í–‰ë™",
        "where": "ì¥ì†Œ"
      }},
      "reason": "ì¼ì • ë¶„ë¥˜ ìƒì„¸ ì´ìœ "
    }}
  ],
  "non_schedules": [
    {{
      "message_id": "ID",
      "content": "ë‚´ìš©",
      "reason": "ì œì™¸ ì´ìœ  (ë‹¨ìˆœëŒ€ë‹µ|ì¼ë°˜ì§ˆë¬¸|ìˆœì„œì„¤ëª…|ì‹œê°„ì„¤ëª…|ì•ˆì£¼ì´ì•¼ê¸° ë“±)"
    }}
  ]
}}
```

**ë¶„ì„í•  ë©”ì‹œì§€ë“¤**:
"""
        
        # ë©”ì‹œì§€ ëª©ë¡ ì¶”ê°€
        for i, msg in enumerate(messages[:10]):
            context_info = f" [ë§¥ë½ê·¸ë£¹: {msg.get('message_count', 1)}ê°œ ë©”ì‹œì§€]" if msg.get('is_context_grouped', False) else ""
            
            # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ì—¬ JSON ì˜¤ë¥˜ ë°©ì§€
            content = msg['content'].replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
            content = ''.join(char for char in content if ord(char) >= 32 or char in '\n\r\t')
            
            prompt += f"""
{i+1}. ID: {msg['id']}
   ë‚´ìš©: "{content}"
   ì‘ì„±ì: {msg['author']}
   ì±„ë„: {msg['channel']}
   ì‹œê°„: {msg['created_at'].strftime('%Y-%m-%d %H:%M')}
   ë§¥ë½: {context_info}
"""
        
        return prompt
    
    async def classify_messages(self, messages):
        """ë©”ì‹œì§€ë“¤ì„ AIë¡œ ë¶„ë¥˜ (ì •ë°€ ì¡°ì • ë²„ì „)"""
        print(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘: {len(messages)}ê°œ ë©”ì‹œì§€")
        
        if not messages:
            print("âŒ ë¶„ë¥˜í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        batch_size = 10
        total_batches = (len(messages) + batch_size - 1) // batch_size
        
        print(f"ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬: {total_batches}ê°œ ë°°ì¹˜ (ë°°ì¹˜ë‹¹ {batch_size}ê°œì”©)")
        print(f"ğŸ’° ì˜ˆìƒ ë¹„ìš©: ì•½ {total_batches * 6:,}ì›")
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, len(messages))
            batch_messages = messages[start_idx:end_idx]
            
            print(f"\nğŸ“Š ë°°ì¹˜ {batch_num + 1}/{total_batches}: {len(batch_messages)}ê°œ ë©”ì‹œì§€ ë¶„ì„ ì¤‘...")
            
            try:
                prompt = self.create_classification_prompt(batch_messages)
                
                try:
                    response = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ë°€í•œ ì¼ì • ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í™•ì‹ ë„ 92% ì´ìƒì¸ ëª…í™•í•œ ì¼ì •ë§Œ ë¶„ë¥˜í•˜ì„¸ìš”."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.1,  # ë‚®ì¶°ì„œ ë” ì •í™•í•˜ê²Œ
                        max_tokens=2500,
                        presence_penalty=0,
                        frequency_penalty=0
                    )
                    
                    response_text = response.choices[0].message.content.strip()
                    
                except Exception as api_error:
                    print(f"  âŒ OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {api_error}")
                    await asyncio.sleep(2)
                    continue
                
                # JSON ì¶”ì¶œ ë° ì •ë¦¬
                if "```json" in response_text:
                    json_start = response_text.find("```json") + 7
                    json_end = response_text.find("```", json_start)
                    response_text = response_text[json_start:json_end].strip()
                
                # JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€
                response_text = ''.join(char for char in response_text if ord(char) >= 32 or char in '\n\r\t')
                
                try:
                    result = json.loads(response_text)
                except json.JSONDecodeError as json_error:
                    print(f"  âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {json_error}")
                    continue
                
                # ì—„ê²©í•œ í›„ì²˜ë¦¬ ê²€ì¦
                validated_schedules = []
                if 'schedules' in result:
                    for schedule in result['schedules']:
                        confidence = schedule.get('confidence', 0)
                        content = schedule.get('content', '').lower()
                        
                        # í™•ì‹ ë„ ê¸°ì¤€ ìƒí–¥: 92% ì´ìƒ
                        if confidence < 0.92:
                            print(f"    âš ï¸ ë‚®ì€ í™•ì‹ ë„ë¡œ ì œì™¸: {confidence:.1%} - {content[:30]}...")
                            continue
                        
                        # ì—„ê²©í•œ í›„ì²˜ë¦¬ í•„í„°ë§
                        false_positive_patterns = [
                            r'.*ëë‚˜ê³ .*ë“œì‹¤',        # "í•©ì£¼ëë‚˜ê³  ë“œì‹¤ ì•ˆì£¼ë‘"
                            r'.*ì€\s*í•©ë‹ˆë‹¤$',       # "í•©ì£¼ì—°ìŠµì€í•©ë‹ˆë‹¤"  
                            r'.*ì‹œê°„\s*ìˆ.*\?',      # "ì‹œê°„ ìˆë‚˜ìš”?"
                            r'.*ìˆœì„œëŒ€ë¡œ',           # "ìˆœì„œëŒ€ë¡œ"
                            r'.*ì€\s*\d+ì‹œê°„',       # "ì„œê³¡ì€ 2ì‹œê°„"
                            r'.*ì€\s*\d+ë¶„',         # "ì¸í„°ë¯¸ì…˜ì€ 15ë¶„"
                            r'ì•ˆì£¼', r'ë“œì‹¤', r'ë¨¹ì„',  # ì‹ì‚¬ ê´€ë ¨
                        ]
                        
                        is_false_positive = False
                        for pattern in false_positive_patterns:
                            if re.search(pattern, content):
                                print(f"    âš ï¸ False Positive í•„í„°ë¡œ ì œì™¸: {pattern} - {content[:30]}...")
                                is_false_positive = True
                                break
                        
                        if not is_false_positive:
                            validated_schedules.append(schedule)
                
                # ê²€ì¦ëœ ì¼ì •ë§Œ ì €ì¥
                self.schedules.extend(validated_schedules)
                print(f"  âœ… ê²€ì¦ëœ ì¼ì •: {len(validated_schedules)}ê°œ")
                
                if 'non_schedules' in result:
                    self.non_schedules.extend(result['non_schedules'])
                    print(f"  âŒ ì¼ì • ì•„ë‹˜: {len(result['non_schedules'])}ê°œ")
                
                await asyncio.sleep(1.5)
                
            except Exception as e:
                print(f"  âŒ ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        self.print_results()
    
    def print_results(self):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        total_messages = len(self.schedules) + len(self.non_schedules)
        
        print(f"\nğŸ¯ AI ë¶„ì„ ì™„ë£Œ!")
        print(f"=" * 70)
        print(f"   ğŸ“… ì¼ì •ìœ¼ë¡œ ë¶„ë¥˜: {len(self.schedules)}ê°œ")
        print(f"   ğŸ’¬ ì¼ì • ì•„ë‹˜: {len(self.non_schedules)}ê°œ")
        
        if total_messages > 0:
            schedule_ratio = len(self.schedules) / total_messages * 100
            print(f"   ğŸ“Š ì¼ì • ë¹„ìœ¨: {schedule_ratio:.1f}%")
        else:
            print(f"   ğŸ“Š ì¼ì • ë¹„ìœ¨: 0% (ë¶„ì„ëœ ë©”ì‹œì§€ ì—†ìŒ)")
        
        if self.schedules:
            print(f"\nğŸ“‹ ë°œê²¬ëœ ì¼ì •ë“¤ (ì •ë°€ ê²€ì¦ ì™„ë£Œ):")
            print("=" * 70)
            for i, schedule in enumerate(self.schedules):
                print(f"\nğŸ“… ì¼ì • #{i+1}:")
                print(f"   ğŸ’¬ ë‚´ìš©: {schedule.get('content', '')}")
                print(f"   ğŸ‘¤ ì‘ì„±ì: {schedule.get('author', 'Unknown')}")
                print(f"   ğŸ¯ ìœ í˜•: {schedule.get('schedule_type', 'Unknown')}")
                print(f"   ğŸ• ì–¸ì œ: {schedule.get('extracted_info', {}).get('when', 'ë¯¸ìƒ')}")
                print(f"   ğŸ“ ë¬´ì—‡: {schedule.get('extracted_info', {}).get('what', 'ë¯¸ìƒ')}")
                print(f"   ğŸ¯ í™•ì‹ ë„: {schedule.get('confidence', 0):.1%}")
                print(f"   ğŸ’­ ì´ìœ : {schedule.get('reason', '')}")
        else:
            print(f"\nğŸ’¡ í™•ì‹¤í•œ ì¼ì •ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print(f"   ğŸ¯ ì •ë°€ ê²€ì¦ìœ¼ë¡œ í™•ì‹¤í•œ ì¼ì •ë§Œ í†µê³¼ì‹œí‚µë‹ˆë‹¤.")

async def classify_schedule_messages(messages):
    """ë©”ì‹œì§€ ë¶„ë¥˜ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¤– AI ì¼ì • ë¶„ë¥˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        return [], []
    
    classifier = ScheduleClassifier()
    await classifier.classify_messages(messages)
    
    return classifier.schedules, classifier.non_schedules
